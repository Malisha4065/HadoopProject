version: '3.8'

services:
  namenode:
    image: apache/hadoop:3.4.1
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - "9870:9870"
      - "8020:8020"
    environment:
      - CLUSTER_NAME=hadoop-cluster
    volumes:
      - hadoop_namenode:/opt/hadoop/dfs/name
      - ./data:/data
      - ./scripts:/scripts
      - ./config:/opt/hadoop/etc/hadoop
    networks:
      - hadoop
    healthcheck:
      test: ["CMD-SHELL", "hdfs dfsadmin -safemode get | grep 'Safe mode is OFF'"]
      interval: 10s
      timeout: 10s
      retries: 30
      start_period: 30s

  datanode:
    image: apache/hadoop:3.4.1
    hostname: datanode
    command: ["hdfs", "datanode"]
    environment:
      - CLUSTER_NAME=hadoop-cluster
    volumes:
      - hadoop_datanode:/opt/hadoop/dfs/data
      - ./data:/data
      - ./scripts:/scripts
      - ./config:/opt/hadoop/etc/hadoop
    networks:
      - hadoop
    depends_on:
      - namenode

  resourcemanager:
    image: apache/hadoop:3.4.1
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
      - "8088:8088"
    environment:
      - CLUSTER_NAME=hadoop-cluster
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./config:/opt/hadoop/etc/hadoop
    networks:
      - hadoop
    depends_on:
      namenode:
        condition: service_healthy
      datanode:
        condition: service_started

  nodemanager:
    image: apache/hadoop:3.4.1
    hostname: nodemanager
    command: ["yarn", "nodemanager"]
    environment:
      - CLUSTER_NAME=hadoop-cluster
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./config:/opt/hadoop/etc/hadoop
    networks:
      - hadoop
    depends_on:
      - resourcemanager

  historyserver:
    image: apache/hadoop:3.4.1
    hostname: historyserver
    command: ["mapred", "historyserver"]
    ports:
      - "19888:19888"
    environment:
      - CLUSTER_NAME=hadoop-cluster
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./config:/opt/hadoop/etc/hadoop
    networks:
      - hadoop
    depends_on:
      namenode:
        condition: service_healthy

  # Client container for compiling and running Java jobs
  hadoop-client:
    #image: apache/hadoop:3.4.1
    build:
      context: .
      dockerfile: Dockerfile.client
    hostname: hadoop-client
    command: ["tail", "-f", "/dev/null"]  # Keep container running
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - ./data:/opt/hadoop/data
      - ./java-src:/opt/hadoop/java-src
      - ./jars:/opt/hadoop/jars
      - ./results:/opt/hadoop/results
      - ./scripts:/opt/hadoop/scripts
      - ./config:/opt/hadoop/etc/hadoop
    networks:
      - hadoop
    depends_on:
      namenode:
        condition: service_healthy
      datanode:
        condition: service_started
      resourcemanager:
        condition: service_started
      nodemanager:
        condition: service_started
    stdin_open: true
    tty: true

volumes:
  hadoop_namenode:
  hadoop_datanode:

networks:
  hadoop:
